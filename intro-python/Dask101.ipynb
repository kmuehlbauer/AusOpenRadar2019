{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple example of parallel computing with Dask on ARM data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dask** is a great tool for taking a problem an distrubuting across many cores. This is a **simple example** as in you really could just do this in series. but it neatly shows how easy it is to map a problem to a cluster.  \n",
    "\n",
    "Now is a great time to learn how to use Dask as there is massive uptake in the community including NSF/NASA funded [Pangeo](https://pangeo.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os # Code for dealing with the file system\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from dask_kubernetes import KubeCluster\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import wait, progress\n",
    "\n",
    "import xarray as xr\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First few cells deal with reading data into an X-Array object and work on ONE data file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For this workshop** We are using Pangeo's Kube cluster set up... I will explain a little in the course..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 10 'workers' under 'manual scaling' menu below and click 'Scale'\n",
    "# Click on the 'Dashboard link' to monitor calculation progress\n",
    "cluster = KubeCluster(n_workers=10, port=33949)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pangeo_tech_1.png)\n",
    "\n",
    "from: http://pangeo.io/architecture.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_directory = os.path.expanduser('~/data/sgpmetE13b1/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and sort a list of files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = os.listdir(in_directory)\n",
    "all_files.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we append the path to each file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fqn_files = [os.path.join(in_directory,thisfile) for thisfile in all_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_name = os.path.join(in_directory, all_files[23])\n",
    "test_dataset = xr.open_dataset(test_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X-Array is awesome. It is very rich and couples very nicely to ARM data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.time[0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot one day's worth of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_figure = plt.figure(figsize=[10,5])\n",
    "test_dataset.temp_mean.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the specific application we want: What is the min, mean and max temperature for a day? (of course this is a UTC day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mean = float(test_dataset.temp_mean.mean())\n",
    "my_max = float(test_dataset.temp_mean.max())\n",
    "my_min = float(test_dataset.temp_mean.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean: {}, Max: {}, Min: {}\".format(my_mean, my_max, my_min ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good housekeeping, close the file (this gets you into all kind of trouble when doing distributed computing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So, here is your Distrubuted computing 101. \n",
    "To use something like Dask you want to break your problem down into repeated tasks. Then instead of looping you do a *Map Reduce*. Create a function that you want to map onto a list of \"things\". In our case it is a function that opens a data file, returns the time, mean, min and max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_this_days_temps(filename):\n",
    "    this_dataset = xr.open_dataset(filename)\n",
    "    my_mean = float(this_dataset.temp_mean.mean())\n",
    "    my_max = float(this_dataset.temp_mean.max())\n",
    "    my_min = float(this_dataset.temp_mean.min())\n",
    "    this_dataset.close()\n",
    "    return this_dataset.time[0].values, my_mean, my_max, my_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test our function on one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_this_days_temps(fqn_files[300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here is the magic!** Map the list of files to the function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = client.map(analyze_this_days_temps, fqn_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show me the PROGRESS!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress(future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it is done gather the data from the complete processes. (Map, then reduce) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = client.gather(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.array([tpl[0] for tpl in my_data])\n",
    "means = np.array([tpl[1] for tpl in my_data])\n",
    "maxs = np.array([tpl[2] for tpl in my_data])\n",
    "mins = np.array([tpl[3] for tpl in my_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_fig = plt.figure(figsize=[10,5])\n",
    "plt.plot(times, means, '-k', label='Mean')\n",
    "plt.plot(times, mins, '-b', label='Min')\n",
    "plt.plot(times, maxs, '-r', label='Max')\n",
    "plt.ylabel('Temperature (C)')\n",
    "plt.xlabel('Time')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
